{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Bosch Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://xujiarudembp.fios-router.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Bosch Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10eb17da0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "num_new_pd = pd.read_csv('new_train_numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.read_csv('train_numeric.csv',usecols=['Response']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_new_pd = pd.concat([num_new_pd,response],axis=1).to_csv('new_train_numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_new = spark.read\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .format('csv')\\\n",
    "  .load('new_train_numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_new = spark.read\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .format('csv')\\\n",
    "  .load('new_train_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_new = spark.read\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .format('csv')\\\n",
    "  .load('new_train_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "new_train = num_new.join(cat_new, [\"_c0\"]).join(date_new, [\"_c0\"]).drop('_c0').drop('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler,Binarizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.sql.functions import to_timestamp, year, month, dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow we have duplicate response columns. Therefore, we drop the unnecessary one.\n",
    "new_train = new_train.drop('Response104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename response column for convenience\n",
    "new_train = new_train.withColumnRenamed(\"Response103\", \"Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in accordance with our previous engineering section\n",
    "new_train = new_train.na.fill(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_and_date_feature:\n",
    "    new_train = new_train.withColumn(col,new_train[col].cast('float'))\n",
    "# new_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 947155\n",
      "Number of testing records : 213200\n",
      "Number of prediction records : 23392\n"
     ]
    }
   ],
   "source": [
    "splitted_data = new_train.randomSplit([0.8, 0.18, 0.02], 666)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "predict_data = splitted_data[2]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))\n",
    "print(\"Number of prediction records : \" + str(predict_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Response'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.columns[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the needed numerical and date columns \n",
    "num_and_date_feature = new_train.columns[1:101]+new_train.columns[111:]\n",
    "len(num_and_date_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_and_date_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringIndexer\n",
    "stringIndexer_L1_S24_F1114 = StringIndexer(inputCol=\"L1_S24_F1114\", outputCol=\"L1_S24_F1114_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S24_F1137 = StringIndexer(inputCol=\"L1_S24_F1137\", outputCol=\"L1_S24_F1137_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S24_F1140 = StringIndexer(inputCol=\"L1_S24_F1140\", outputCol=\"L1_S24_F1140_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S24_F1510 = StringIndexer(inputCol=\"L1_S24_F1510\", outputCol=\"L1_S24_F1510_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S24_F1525 = StringIndexer(inputCol=\"L1_S24_F1525\", outputCol=\"L1_S24_F1525_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S24_F1530 = StringIndexer(inputCol=\"L1_S24_F1530\", outputCol=\"L1_S24_F1530_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S25_F1852 = StringIndexer(inputCol=\"L1_S25_F1852\", outputCol=\"L1_S25_F1852_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L1_S25_F2779 = StringIndexer(inputCol=\"L1_S25_F2779\", outputCol=\"L1_S25_F2779_IX\",handleInvalid=\"keep\")\n",
    "stringIndexer_L3_S32_F3854 = StringIndexer(inputCol=\"L3_S32_F3854\", outputCol=\"L3_S32_F3854_IX\",handleInvalid=\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols = [col for col in num_and_date_feature] + [\"L1_S24_F1114_IX\",\"L1_S24_F1137_IX\",\"L1_S24_F1140_IX\",\n",
    "              \"L1_S24_F1510_IX\",\"L1_S24_F1525_IX\",\"L1_S24_F1530_IX\",\"L1_S25_F1852_IX\",\n",
    "               \"L1_S25_F2779_IX\",\"L3_S32_F3854_IX\"],\n",
    "    outputCol=\"features\",handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_b87992bc41da"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorAssembler_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(labelCol=\"Response\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logit = Pipeline(stages=[stringIndexer_L1_S24_F1114, stringIndexer_L1_S24_F1137, \n",
    "                               stringIndexer_L1_S24_F1140, stringIndexer_L1_S24_F1510,\n",
    "                               stringIndexer_L1_S24_F1525, stringIndexer_L1_S24_F1530,\n",
    "                               stringIndexer_L1_S25_F1852, stringIndexer_L1_S25_F2779,\n",
    "                               stringIndexer_L3_S32_F3854,\n",
    "                               vectorAssembler_features, \n",
    "                               logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logit = pipeline_logit.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logit = model_logit.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|213198|\n",
      "|       1.0|     2|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_logit.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = predictions_logit.select('prediction','Response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Response| count|\n",
      "+--------+------+\n",
      "|     1.0|  1248|\n",
      "|     0.0|211952|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The real structure for response in our test dataset\n",
    "test_data.groupBy('Response').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred.filter(\"Response == 1 \").filter(\"prediction == 1\").count() # True Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred.filter(\"Response == 1 \").filter(\"prediction == 0\").count() # False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred.filter(\"Response == 0 \").filter(\"prediction == 1\").count() # False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211951"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pred.filter(\"Response == 0 \").filter(\"prediction == 0\").count() # True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01983993227463039"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "tp = 1\n",
    "fp = 1\n",
    "fn = 1247\n",
    "tn = 211952\n",
    "mcc = (tp*tn - fp*fn) /( math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions.select('prediction','Response').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionAndLabels.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "# evaluatorLogit = BinaryClassificationMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluatorLogit.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial RandomForest model.\n",
    "# rf = RandomForestClassifier(labelCol=\"Response\", featuresCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_rf = Pipeline(stages=[stringIndexer_L1_S24_F1114, stringIndexer_L1_S24_F1137, \n",
    "#                                stringIndexer_L1_S24_F1140, stringIndexer_L1_S24_F1510,\n",
    "#                                stringIndexer_L1_S24_F1525, stringIndexer_L1_S24_F1530,\n",
    "#                                stringIndexer_L1_S25_F1852, stringIndexer_L1_S25_F2779,\n",
    "#                                stringIndexer_L3_S32_F3854,\n",
    "#                                vectorAssembler_features, \n",
    "#                                rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_rf = pipeline_rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model_rf.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionAndLabels_rf = predictions.select('prediction','Response').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluatorRF = BinaryClassificationMetrics(predictionAndLabels_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluatorRF.areaUnderROC -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.groupBy('prediction').count().show()  - prediction has no 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|213148|\n",
      "|       1.0|    52|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"Response\", featuresCol=\"features\")\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline_gbt = Pipeline(stages=[stringIndexer_L1_S24_F1114, stringIndexer_L1_S24_F1137, \n",
    "                               stringIndexer_L1_S24_F1140, stringIndexer_L1_S24_F1510,\n",
    "                               stringIndexer_L1_S24_F1525, stringIndexer_L1_S24_F1530,\n",
    "                               stringIndexer_L1_S25_F1852, stringIndexer_L1_S25_F2779,\n",
    "                               stringIndexer_L3_S32_F3854,\n",
    "                               vectorAssembler_features, \n",
    "                               gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "gbt_model = pipeline_gbt.fit(train_data)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_gbt = gbt_model.transform(test_data)\n",
    "predictions_gbt.groupBy('prediction').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the count table above, we notice that we are doing a far more better job than the previous two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_pred = predictions_gbt.select('prediction','Response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_pred.filter(\"Response == 1 \").filter(\"prediction == 1\").count() # True Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_pred.filter(\"Response == 1 \").filter(\"prediction == 0\").count() # False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_pred.filter(\"Response == 0 \").filter(\"prediction == 1\").count() # False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211925"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_pred.filter(\"Response == 0 \").filter(\"prediction == 0\").count() # True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09723857799358827"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "tp = 25\n",
    "fp = 27\n",
    "fn = 1223\n",
    "tn = 211925\n",
    "mcc = (tp*tn - fp*fn) /( math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, in modeling part, we have gone through different classfication methods, such as **Logistic Regression, Random Forest and Gradient-boosted tree classifier**. According to each result, we find out that **Gradient-boosted tree** has the best predictability. As for evaluation method, we choose **Matthews correlation coefficient** to prevent the effect of data imbalance. We adopt classfication metric to look into in what proportion we are doing things right and making mistakes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
